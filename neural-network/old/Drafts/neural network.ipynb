{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import e\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self, p):\n",
    "        self.p1 = p[0]\n",
    "        self.p2 = p[1]\n",
    "        self.slope = (self.p1[1]-self.p2[1])/(self.p1[0]-self.p2[0])\n",
    "        self.b = self.p1[1]-self.slope*self.p1[0]\n",
    "        super().__init__()\n",
    "    def calculate(self,x):\n",
    "        return self.slope*x+self.b\n",
    "    def plot(self):\n",
    "        x = np.random.uniform(-1,1,10)\n",
    "        plt.plot(x,self.calculate(x))\n",
    "    def find_actual_y(self,points):\n",
    "        return [np.sign(self.calculate(p[0]) - p[1]) for p in points]\n",
    "\n",
    "    \n",
    "#for layer 1, i=[0-2] and j=[0-2]\n",
    "#for layer 2, i=[0-4] and j=[1]\n",
    "    \n",
    "class NeuralNetwork(Line):\n",
    "    def __init__(self):\n",
    "        self.N = 10\n",
    "        self.input = 2\n",
    "        self.N_var_layer1 = 3\n",
    "        self.N_var_layer2 = 4\n",
    "        self.N_var_layer3 = 1 #output\n",
    "        self.layers = [self.N_var_layer1, self.N_var_layer2, self.N_var_layer3]\n",
    "        self.n = .1\n",
    "        self.N_layers = len(self.layers)\n",
    "        \n",
    "        #initialize weights\n",
    "        self.weights1 = np.random.uniform(-1.0,1.0,(self.N_var_layer2-1,self.N_var_layer1)) # shape =(#j (outputs), #i (inputs))\n",
    "        self.weights2 = np.random.uniform(-1.0,1.0,(self.N_var_layer3,self.N_var_layer2))\n",
    "        self.weights = [self.weights1,self.weights2]\n",
    "        \n",
    "        #Create points\n",
    "        self.create_line()\n",
    "        X = np.random.uniform(-1.0,1.0,(self.N,self.input))\n",
    "        self.y = self.find_actual_y(X)\n",
    "        self.X = np.concatenate([[[1]for x in range(len(X))],X],axis=1)\n",
    "\n",
    "        #Run SGD\n",
    "        \n",
    "        mse = self.mse(self.X,self.y)\n",
    "        print(mse)\n",
    "        \n",
    "        for x in range(1):\n",
    "            wt = self.vals()\n",
    "            self.sgd_epoch()\n",
    "            wt1 = self.vals()\n",
    "            \n",
    "        \n",
    "        \n",
    "        mse = self.mse(self.X,self.y)\n",
    "        print(mse)\n",
    "        \n",
    "        self.eout = self.eout()\n",
    "        print(self.eout)\n",
    "        \n",
    "    def create_line(self):\n",
    "        p = np.random.uniform(-1.0,1.0,(2,2))\n",
    "        while p[0][0] == p[1][0] and p[0][1] == p[1][1]:\n",
    "            p = [np.random.uniform(-1.0,1.0,2) for x in range(2)]\n",
    "        super().__init__(p)\n",
    "         \n",
    "        \n",
    "        \n",
    "####################################################\n",
    "    def vals(self):\n",
    "        change = []\n",
    "        for layer in range(2,self.N_layers+1):\n",
    "                layer_m1 = layer -1\n",
    "                jss = [0] if layer == self.N_layers else range(self.layers[layer-1]-1)\n",
    "                iss = range(self.layers[layer_m1-1]) \n",
    "                change += [self.weights[layer_m1-1][j][i] for i in iss for j in jss]\n",
    "        return change \n",
    "    \n",
    "    def pickRandomPoint(self):\n",
    "        val = random.randint(0,self.N-1)\n",
    "        return self.X[val], self.y[val]\n",
    "        \n",
    "    def calculate_xjLs(self,x):\n",
    "        xjLs = [x]\n",
    "        for layer in range(self.N_layers-1):\n",
    "            x_l = [1] if layer != self.N_layers-2 else [] #self.N_layers-2 bc layer 2nd gives layer 3 and layer 2nd is actually 1\n",
    "            weights_for_layer = self.weights[layer]\n",
    "            for w_jl in weights_for_layer: #picking specific weights of one output (j)\n",
    "                x_jl = self.tahn(np.matmul(x,w_jl.T))\n",
    "                x_l.append(x_jl)\n",
    "            xjLs.append(x_l)\n",
    "            x = x_l\n",
    "        return xjLs\n",
    "    \n",
    "    def tahn(self,sj):\n",
    "        return (e**sj-e**-sj)/(e**sj+e**-sj)\n",
    "    \n",
    "    def derivative_of_tahn(self,tahn_s):\n",
    "        return (1-(tahn_s)**2)\n",
    "    \n",
    "    def calculate_deltaL(self,x,y):\n",
    "        x_1_L = self.xjLs[self.N_layers-1][0]\n",
    "        return [(x_1_L-y)*self.derivative_of_tahn(x_1_L)]\n",
    "    \n",
    "    def calculate_deltas(self,layer,deltas_layer):\n",
    "        #when layer is three gives deltas for two (already made deltaL), when layer is 2 it gives deltas for 1 --> stop at layer 2\n",
    "        if layer == 2:\n",
    "            return [deltas_layer]\n",
    "        layer_m1 = layer-1\n",
    "        d_layer = [1] if layer == self.N_layers else range(1,self.layers[layer_m1]) \n",
    "        d_layer_m1 = range(1,self.layers[layer_m1-1]) \n",
    "        \n",
    "        deltas_layer_m1_i = []\n",
    "        \n",
    "        for i in d_layer_m1:\n",
    "            sum_of_j_paths = 0\n",
    "            for j in d_layer:\n",
    "                deltaj = deltas_layer[j-1]\n",
    "                sum_of_j_paths += deltaj*self.weights[layer_m1-1][j-1][i] \n",
    "                #j-1 because the weights for j=1 are actually the first weights as j=0 is 1\n",
    "            \n",
    "            delta_layer_m1_i = self.derivative_of_tahn(self.xjLs[layer_m1-1][i]) * sum_of_j_paths\n",
    "            deltas_layer_m1_i.append(delta_layer_m1_i)\n",
    "            \n",
    "        return self.calculate_deltas(layer-1,deltas_layer_m1_i) + [deltas_layer]\n",
    "        \n",
    "    \n",
    "####################################################\n",
    "    \n",
    "    \n",
    "    def sgd_gradient(self):\n",
    "        for layer in range(2,self.N_layers+1):\n",
    "            layer_m1 = layer-1 #wij_2 where 2=layer is the weights between layer 1 (layer-1) and layer 2 (layer)\n",
    "            delta_layer = self.deltas[layer-2] #delta layer 2 is the first delta at index 0\n",
    "            for j in range(1,self.layers[layer-1]):\n",
    "                deltaj_l = delta_layer[j-1]\n",
    "                for i in range(self.layers[layer_m1-1]):\n",
    "                    wij_l = self.weights[layer_m1-1][j-1][i]#weights for layer 1 to go to layer 2 is at index 0\n",
    "                    xi_layer_m1 = self.xjLs[layer_m1-1][i]\n",
    "                    gradient = -self.n*xi_layer_m1*deltaj_l\n",
    "                    self.weights[layer_m1-1][j-1][i] = wij_l + gradient\n",
    "        \n",
    "        \n",
    "        \n",
    "    def sgd_epoch(self):\n",
    "        vals = list(range(self.N))\n",
    "        random.shuffle(vals)\n",
    "        for v in vals:\n",
    "            x, y = self.X[v],self.y[v]\n",
    "            self.xjLs = self.calculate_xjLs(x)\n",
    "            self.deltaL = self.calculate_deltaL(x,y)\n",
    "            self.deltas = self.calculate_deltas(self.N_layers,self.deltaL)\n",
    "            self.sgd_gradient()\n",
    "              \n",
    "    \n",
    "    \n",
    "######################################################\n",
    "        \n",
    "    def mse(self,X,y):\n",
    "        w = self.weights\n",
    "        return sum([(self.calculate_xjLs(X[v])[-1][0] - y[v])**2 for v in range(len(X))])/len(X)\n",
    "    \n",
    "    \n",
    "    def eout(self):\n",
    "        X = [np.random.uniform(-1.0,1.0,2) for x in range(100)]\n",
    "        X = np.concatenate([[[1]for x in range(len(X))],X],axis=1)\n",
    "        y = self.find_actual_y(X)\n",
    "        return self.mse(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6452980447037924\n",
      "[0.6179884974087972, -0.9111338786784737, 0.17594361393558366, -0.62277240828293, 0.18587438210634888, 0.8237992359789024, 0.31897663805073617, -0.3957047891116219, -0.8152277622567687, -0.5377258774558933, 0.33997308229687495, 0.9995786597842886, -0.500583813443986] [0.6835553557384143, -0.6829463198658073, 0.04371032036982899, -0.6508738536311175, 0.08972917694062463, 0.8951997766803389, 0.26362913029333856, -0.5671682458151135, -0.7220881332285297, -0.5377258774558933, 0.33997308229687495, 0.9995786597842886, -0.500583813443986]\n",
      "1.3431672286723144\n",
      "1.8231112983103543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetwork at 0x7ffd61243910>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([1,1])\n",
    "y = t.copy()\n",
    "print(y)\n",
    "t[[0,1]] = 3\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "k = {\"1\":1}\n",
    "k[str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.26713872,  0.1147905 ])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all that will have deltas from layer 2(the layer minus 1) is from i's 1-3 bc those are the ones where the previous layers will need their deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j-1 because the weights for j=1 are actually the first weights from the prev layer to that layer as j=0 is 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
